{{- range .Values.cascade.hyperpool.models }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .name }}
  labels:
    app.kubernetes.io/name: {{ .name }}
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ .name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ .name }}
    spec:
      priorityClassName: {{ .name }}
      containers:
        - name: vllm-server
          image: vllm/vllm-openai:v0.8.5
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8000
              name: http
            - containerPort: 9999
              name: metrics
          args:
            # https://docs.vllm.ai/en/latest/getting_started/quickstart.html#quickstart-online
            - "--model"
            - {{ .model }}
            {{- range .extraArgs}}
            - {{ . }}
            {{- end}}
          {{- with .resources }}
          resources:
            {{- toYaml . | nindent 12 }}
          {{ end }}
          volumeMounts:
            - name: models
              mountPath: /models
      volumes:
        - name: models
          hostPath:
            path: /var/lib/hyperpool/models
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      terminationGracePeriodSeconds: {{ .Values.terminationGracePeriodSeconds }}
{{- end }}
