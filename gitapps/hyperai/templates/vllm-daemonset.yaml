---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: hyperai-vllm-daemon
  labels:
    app.kubernetes.io/name: hyperai-vllm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hyperai-vllm
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hyperai-vllm
    spec:
      priorityClassName: hyperai
      containers:
      - name: vllm-server
        image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
        imagePullPolicy: {{ .Values.image.pullPolicy | default "IfNotPresent" }}
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 9999
          name: metrics
        args:
          # https://docs.vllm.ai/en/latest/getting_started/quickstart.html#quickstart-online
          - "--model"
          - {{ .Values.cascade.hyperai.model.name }}
          # required to get things to run on T4
          - "--dtype=half"
        {{- with .Values.resources }}
        resources:
          {{- toYaml . | nindent 10 }}
        {{ end }}
        volumeMounts:
        - name: models
          mountPath: /models
      volumes:
      - name: models
        hostPath:
          path: /var/lib/hyperai/models
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
